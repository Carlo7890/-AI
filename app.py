import streamlit as st
import pandas as pd
import re
import requests

# CSV ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    words_df = pd.read_csv("ì‚¬ê³ ë„êµ¬ì–´_ë‹¨ì–´ë“±ê¸‰ë§¤í•‘.csv", encoding='euc-kr')
    score_df = pd.read_csv("ì˜¨ë…ì§€ìˆ˜ë²”ìœ„.csv", encoding='utf-8')

    # ì˜¨ë…ì§€ìˆ˜ ë²”ìœ„ íŒŒì‹±
    score_df[['min', 'max']] = score_df['ì˜¨ë…ì§€ìˆ˜ ë²”ìœ„'].str.split('~', expand=True).astype(int)

    return words_df, score_df

# í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ê³ ë„êµ¬ì–´ ì¶”ì¶œ
def extract_words(text, word_list):
    return [word for word in word_list if word in text]

# ì˜¨ë…ì§€ìˆ˜ ê³„ì‚° (ë…¼ë¬¸ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ ì ìš©)
def calculate_ondok_score_v2(matched_df, total_tokens):
    if matched_df.empty or total_tokens == 0:
        return 0

    # ë“±ê¸‰ë³„ STTR ë³´ì •ì¹˜ (ë…¼ë¬¸ ì°¸ê³  ê¸°ì¤€ê°’ ì˜ˆì‹œ)
    sttr_weights = {1: 0.73, 2: 0.68, 3: 0.61, 4: 0.55}

    # ì¡°ì • ì¶œí˜„ ë¹„ìœ¨ = ì¶œí˜„ ìˆ˜ / ì „ì²´ í† í° ìˆ˜ * STTR
    matched_df['ë³´ì •ë¹„ìœ¨'] = matched_df['ë“±ê¸‰'].apply(lambda g: sttr_weights[g])
    adjusted_ratio_sum = len(matched_df) / total_tokens * matched_df['ë³´ì •ë¹„ìœ¨'].mean()

    # ì˜¨ë…ì§€ìˆ˜ ìŠ¤ì¼€ì¼ ì¡°ì • (100~280 ì‚¬ì´ë¡œ ì •ê·œí™”)
    score = adjusted_ratio_sum * 500  # ë³´ì •ê°’
    score = max(0, min(score, 280))
    return score

# í•™ë…„ ë³€í™˜
def estimate_grade(score, score_df):
    for _, row in score_df.iterrows():
        if row['min'] <= score <= row['max']:
            return row['ëŒ€ìƒ í•™ë…„']
    return "ë²”ìœ„ ì™¸"

# Groq ê¸°ë°˜ LLaMA3 ìš”ì•½ ê¸°ëŠ¥

def llama3_summary(text):
    headers = {
        "Authorization": f"Bearer YOUR_GROQ_API_KEY",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama3-70b-8192",
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ë…ì„œì§€ìˆ˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì‚¬ìš©ëœ ì‚¬ê³ ë„êµ¬ì–´ì™€ ì˜ë¯¸ë¥¼ ê°„ë‹¨íˆ ë¶„ì„í•´ì¤˜:\n{text}"}
        ]
    }
    try:
        res = requests.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload)
        return res.json()['choices'][0]['message']['content']
    except:
        return "LLM ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# Streamlit ì•± ì‹œì‘
st.title("ğŸ“š ì˜¨ë…AI: ì‚¬ê³ ë„êµ¬ì–´ ê¸°ë°˜ ë…ì„œì§€ìˆ˜ ë¶„ì„")

text_input = st.text_area("âœï¸ ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:")
run_button = st.button("ğŸ” ë¶„ì„í•˜ê¸°")

if run_button and text_input:
    words_df, score_df = load_data()
    word_list = words_df['ë‹¨ì–´'].tolist()
    used_words = extract_words(text_input, word_list)
    matched_df = words_df[words_df['ë‹¨ì–´'].isin(used_words)].copy()

    if matched_df.empty:
        st.warning("ì‚¬ê³ ë„êµ¬ì–´ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ì–´ìš”.")
    else:
        total_tokens = len(re.findall(r'\b\w+\b', text_input))
        score = calculate_ondok_score_v2(matched_df, total_tokens)
        grade = estimate_grade(score, score_df)

        st.success(f"ğŸ§  ì˜¨ë…ì§€ìˆ˜: {score:.1f}ì ")
        st.info(f"ğŸ“ ì¶”ì • í•™ë…„ ìˆ˜ì¤€: {grade}")
        st.dataframe(matched_df[['ë‹¨ì–´', 'ë“±ê¸‰']].reset_index(drop=True))

        st.markdown("---")
        st.subheader("ğŸ§  LLaMA3 ìš”ì•½ ë¶„ì„ ê²°ê³¼")
        st.write(llama3_summary(text_input))


